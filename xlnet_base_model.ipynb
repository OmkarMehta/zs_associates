{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xlnet_base_model",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO9M-WrdRiEh",
        "colab_type": "code",
        "outputId": "fae0e999-729f-4764-9880-6b3bfa09d759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install fast-bert\n",
        "\n",
        "!git clone https://github.com/NVIDIA/apex\n",
        "\n",
        "!pip install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./apex"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fast-bert in /usr/local/lib/python3.6/dist-packages (1.6.2)\n",
            "Requirement already satisfied: python-box in /usr/local/lib/python3.6/dist-packages (from fast-bert) (4.0.4)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from fast-bert) (0.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (from fast-bert) (2.0)\n",
            "Requirement already satisfied: pytorch-lamb in /usr/local/lib/python3.6/dist-packages (from fast-bert) (1.0.0)\n",
            "Requirement already satisfied: fastprogress in /usr/local/lib/python3.6/dist-packages (from fast-bert) (0.2.2)\n",
            "Requirement already satisfied: transformers>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from fast-bert) (2.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fast-bert) (0.25.3)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.6/dist-packages (from fast-bert) (0.2.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fast-bert) (2.1.9)\n",
            "Requirement already satisfied: ruamel.yaml in /usr/local/lib/python3.6/dist-packages (from python-box->fast-bert) (0.16.7)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from python-box->fast-bert) (0.10.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->fast-bert) (0.22.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX->fast-bert) (1.17.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->fast-bert) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->fast-bert) (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-lamb->fast-bert) (4.28.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pytorch-lamb->fast-bert) (0.4.2)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lamb->fast-bert) (1.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->fast-bert) (2.21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->fast-bert) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->fast-bert) (0.1.85)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->fast-bert) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->fast-bert) (1.10.47)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.3.0->fast-bert) (0.0.38)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->fast-bert) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fast-bert) (2018.9)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fast-bert) (1.0.1)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fast-bert) (0.2.4)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fast-bert) (0.9.6)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from spacy->fast-bert) (2.0.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fast-bert) (0.6.0)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in /usr/local/lib/python3.6/dist-packages (from spacy->fast-bert) (7.0.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fast-bert) (2.0.3)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fast-bert) (1.0.2)\n",
            "Requirement already satisfied: ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from ruamel.yaml->python-box->fast-bert) (0.2.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->fast-bert) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn->fast-bert) (0.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX->fast-bert) (42.0.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pytorch-lamb->fast-bert) (6.2.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->fast-bert) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->fast-bert) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->fast-bert) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.3.0->fast-bert) (3.0.4)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->fast-bert) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->fast-bert) (1.13.47)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.3.0->fast-bert) (0.2.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.3.0->fast-bert) (7.0)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers>=2.3.0->fast-bert) (0.15.2)\n",
            "fatal: destination path 'apex' already exists and is not an empty directory.\n",
            "/usr/local/lib/python3.6/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-ds1j_4dl\n",
            "Created temporary directory: /tmp/pip-req-tracker-fd2fz90_\n",
            "Created requirements tracker '/tmp/pip-req-tracker-fd2fz90_'\n",
            "Created temporary directory: /tmp/pip-install-11p05xex\n",
            "Processing ./apex\n",
            "  Created temporary directory: /tmp/pip-req-build-xohr7t5n\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-fd2fz90_'\n",
            "    Running setup.py (path:/tmp/pip-req-build-xohr7t5n/setup.py) egg_info for package from file:///content/apex\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "    Warning: Torch did not find available GPUs on this system.\n",
            "     If your intention is to cross-compile, this is not an error.\n",
            "    By default, Apex will cross-compile for Pascal (compute capabilities 6.0, 6.1, 6.2),\n",
            "    Volta (compute capability 7.0), and Turing (compute capability 7.5).\n",
            "    If you wish to cross-compile for a single specific architecture,\n",
            "    export TORCH_CUDA_ARCH_LIST=\"compute capability\" before running setup.py.\n",
            "\n",
            "    torch.__version__  =  1.3.1\n",
            "    running egg_info\n",
            "    creating /tmp/pip-req-build-xohr7t5n/pip-egg-info/apex.egg-info\n",
            "    writing /tmp/pip-req-build-xohr7t5n/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-req-build-xohr7t5n/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-req-build-xohr7t5n/pip-egg-info/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-req-build-xohr7t5n/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-req-build-xohr7t5n/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-xohr7t5n/setup.py:43: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-xohr7t5n has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-fd2fz90_'\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "  Found existing installation: apex 0.1\n",
            "    Uninstalling apex-0.1:\n",
            "      Created temporary directory: /tmp/pip-uninstall-srm4ywti\n",
            "      Removing file or directory /usr/local/lib/python3.6/dist-packages/amp_C.cpython-36m-x86_64-linux-gnu.so\n",
            "      Created temporary directory: /usr/local/lib/python3.6/dist-packages/~pex-0.1-py3.6.egg-info\n",
            "      Removing file or directory /usr/local/lib/python3.6/dist-packages/apex-0.1-py3.6.egg-info\n",
            "      Created temporary directory: /usr/local/lib/python3.6/dist-packages/~pex\n",
            "      Removing file or directory /usr/local/lib/python3.6/dist-packages/apex/\n",
            "      Removing file or directory /usr/local/lib/python3.6/dist-packages/apex_C.cpython-36m-x86_64-linux-gnu.so\n",
            "      Removing file or directory /usr/local/lib/python3.6/dist-packages/fused_layer_norm_cuda.cpython-36m-x86_64-linux-gnu.so\n",
            "      Removing file or directory /usr/local/lib/python3.6/dist-packages/syncbn.cpython-36m-x86_64-linux-gnu.so\n",
            "      Successfully uninstalled apex-0.1\n",
            "  Created temporary directory: /tmp/pip-record-v37tje0f\n",
            "    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-xohr7t5n/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-xohr7t5n/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-v37tje0f/install-record.txt --single-version-externally-managed --compile\n",
            "\n",
            "    Warning: Torch did not find available GPUs on this system.\n",
            "     If your intention is to cross-compile, this is not an error.\n",
            "    By default, Apex will cross-compile for Pascal (compute capabilities 6.0, 6.1, 6.2),\n",
            "    Volta (compute capability 7.0), and Turing (compute capability 7.5).\n",
            "    If you wish to cross-compile for a single specific architecture,\n",
            "    export TORCH_CUDA_ARCH_LIST=\"compute capability\" before running setup.py.\n",
            "\n",
            "    torch.__version__  =  1.3.1\n",
            "    /tmp/pip-req-build-xohr7t5n/setup.py:43: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "    No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n",
            "\n",
            "    Compiling cuda extensions with\n",
            "    nvcc: NVIDIA (R) Cuda compiler driver\n",
            "    Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "    Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "    Cuda compilation tools, release 10.1, V10.1.243\n",
            "    from /usr/local/cuda/bin\n",
            "\n",
            "    running install\n",
            "    running build\n",
            "    running build_py\n",
            "    creating build\n",
            "    creating build/lib.linux-x86_64-3.6\n",
            "    creating build/lib.linux-x86_64-3.6/apex\n",
            "    copying apex/__init__.py -> build/lib.linux-x86_64-3.6/apex\n",
            "    creating build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/weight_norm.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/__init__.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    copying apex/reparameterization/reparameterization.py -> build/lib.linux-x86_64-3.6/apex/reparameterization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_lamb.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_novograd.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    copying apex/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/amp.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/wrap.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/scaler.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/opt.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/utils.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/frontend.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/rnn_compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/__version__.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_initialize.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_process_optimizer.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/handle.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/compat.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    copying apex/amp/_amp_state.py -> build/lib.linux-x86_64-3.6/apex/amp\n",
            "    creating build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/__init__.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/fp16util.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    copying apex/fp16_utils/loss_scaler.py -> build/lib.linux-x86_64-3.6/apex/fp16_utils\n",
            "    creating build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/models.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/RNNBackend.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/__init__.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    copying apex/RNN/cells.py -> build/lib.linux-x86_64-3.6/apex/RNN\n",
            "    creating build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/__init__.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    copying apex/normalization/fused_layer_norm.py -> build/lib.linux-x86_64-3.6/apex/normalization\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    copying apex/pyprof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    copying apex/contrib/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib\n",
            "    creating build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    copying apex/multi_tensor_apply/__init__.py -> build/lib.linux-x86_64-3.6/apex/multi_tensor_apply\n",
            "    creating build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/distributed.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/__init__.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/LARC.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/multiproc.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    copying apex/parallel/sync_batchnorm_kernel.py -> build/lib.linux-x86_64-3.6/apex/parallel\n",
            "    creating build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/__init__.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/functional_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/torch_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    copying apex/amp/lists/tensor_overrides.py -> build/lib.linux-x86_64-3.6/apex/amp/lists\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/nvmarker.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    copying apex/pyprof/nvtx/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/nvtx\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/db.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/nvvp.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/kernel.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    copying apex/pyprof/parse/parse.py -> build/lib.linux-x86_64-3.6/apex/pyprof/parse\n",
            "    creating build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pooling.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/loss.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/randomSample.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/dropout.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/output.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/linear.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/activation.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/softmax.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/misc.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/utility.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/convert.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/optim.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/blas.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/base.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/reduction.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/recurrentCell.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/usage.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/conv.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__main__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/normalization.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/__init__.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/data.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/pointwise.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/prof.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    copying apex/pyprof/prof/embedding.py -> build/lib.linux-x86_64-3.6/apex/pyprof/prof\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_sgd.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    copying apex/contrib/optimizers/fused_adam.py -> build/lib.linux-x86_64-3.6/apex/contrib/optimizers\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/batch_norm.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    copying apex/contrib/groupbn/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/groupbn\n",
            "    creating build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    copying apex/contrib/xentropy/__init__.py -> build/lib.linux-x86_64-3.6/apex/contrib/xentropy\n",
            "    running build_ext\n",
            "    building 'apex_C' extension\n",
            "    creating build/temp.linux-x86_64-3.6\n",
            "    creating build/temp.linux-x86_64-3.6/csrc\n",
            "    x86_64-linux-gnu-gcc -pthread -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.6/dist-packages/torch/include -I/usr/local/lib/python3.6/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.6/dist-packages/torch/include/TH -I/usr/local/lib/python3.6/dist-packages/torch/include/THC -I/usr/include/python3.6m -c csrc/flatten_unflatten.cpp -o build/temp.linux-x86_64-3.6/csrc/flatten_unflatten.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=apex_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mh7aIwP2vcOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch_transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7-tn4pYRrbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data handling and processing\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from fast_bert.data_cls import BertDataBunch\n",
        "from pytorch_transformers import BertTokenizer\n",
        "import torch\n",
        "\n",
        "import collections\n",
        "from tqdm import tqdm, trange\n",
        "import sys\n",
        "import random\n",
        "#import apex\n",
        "import datetime\n",
        "\n",
        "from fast_bert.modeling import BertForMultiLabelSequenceClassification\n",
        "from fast_bert.data_cls import BertDataBunch, InputExample, InputFeatures, MultiLabelTextProcessor, convert_examples_to_features\n",
        "from fast_bert.learner_cls import BertLearner\n",
        "from fast_bert.metrics import accuracy_multilabel, accuracy_thresh, fbeta, roc_auc\n",
        "from fast_bert.data_cls import BertDataBunch\n",
        "from fast_bert.learner_cls import BertLearner\n",
        "from fast_bert.metrics import accuracy\n",
        "from fast_bert.prediction import BertClassificationPredictor\n",
        "\n",
        "import logging\n",
        "\n",
        "logger = logging.getLogger()\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "pd.set_option('display.max_colwidth', -1)\n",
        "run_start_time = datetime.datetime.today().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "\n",
        "#data_preprocessing\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from nltk.corpus import stopwords\n",
        "from nltk import word_tokenize\n",
        "from string import punctuation\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from bs4 import BeautifulSoup \n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn import metrics\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.model_selection import KFold, train_test_split\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "##import dataset\n",
        "dataset = pd.read_excel('train.xlsx')\n",
        "\n",
        "##Fill missing values of Host with that link in the same row\n",
        "for i in list(dataset[dataset['Host'].isnull() == True]['Host'].index):\n",
        "    dataset.at[i,'Host'] = dataset.loc[i]['Link']\n",
        "    \n",
        "##Filling missing value of TRANS_CONV_TEXT with that of title\n",
        "for i in list(dataset[dataset['TRANS_CONV_TEXT'].isnull() == True].index):\n",
        "    dataset.at[i, 'TRANS_CONV_TEXT'] = dataset.loc[i]['Title']\n",
        "##Converting 'Date(ET)' object to datetime\n",
        "dataset['Date(ET)'] = pd.to_datetime(dataset['Date(ET)'], infer_datetime_format=True)    \n",
        "\n",
        "##Converting Datetime to timestamp\n",
        "dataset['Date(ET)'] = dataset[['Date(ET)']].apply(lambda x: x[0].timestamp(), axis = 1).astype(int)\n",
        "\n",
        "##Dropping time(ET) and time(GMT)\n",
        "dataset.drop(['Date(ET)', 'Time(ET)', 'time(GMT)'], axis = 1, inplace = True)\n",
        "\n",
        "##Fill missing values of Title with that of TRANS_CONV_TEXT in the same row\n",
        "for i in list(dataset[dataset['Title'].isnull() == True]['Title'].index):\n",
        "    dataset.at[i,'Title'] = dataset.loc[i]['TRANS_CONV_TEXT']\n",
        "\n",
        "## TEST Data\n",
        "test = pd.read_csv('test.csv', encoding = 'utf-8')\n",
        "\n",
        "##Fill missing values of Host with that link in the same row\n",
        "for i in list(test[test['Host'].isnull() == True]['Host'].index):\n",
        "    test.at[i,'Host'] = test.loc[i]['Link']\n",
        "    \n",
        "#Filling missing value of TRANS_CONV_TEXT with that of title\n",
        "for i in list(test[test['TRANS_CONV_TEXT'].isnull() == True].index):\n",
        "    test.at[i, 'TRANS_CONV_TEXT'] = test.loc[i]['Title']\n",
        "\n",
        "test.at[441,'Date(ET)'] = test.loc[441, 'Time(ET)']\n",
        "\n",
        "#Converting 'Date(ET)' object to datetime\n",
        "test['Date(ET)'] = pd.to_datetime(test['Date(ET)'], infer_datetime_format=True)    \n",
        "\n",
        "#Converting Datetime to timestamp\n",
        "test['Date(ET)'] = test[['Date(ET)']].apply(lambda x: x[0].timestamp(), axis = 1).astype(int)\n",
        "\n",
        "#Dropping time(ET) and time(GMT)\n",
        "test.drop(['Date(ET)','Time(ET)', 'time(GMT)'], axis = 1, inplace = True)\n",
        "\n",
        "#Fill missing values of Title with that of TRANS_CONV_TEXT in the same row\n",
        "for i in list(test[test['Title'].isnull() == True]['Title'].index):\n",
        "    test.at[i,'Title'] = test.loc[i]['TRANS_CONV_TEXT']\n",
        "\n",
        "index = test['Index']\n",
        "index = list(index)\n",
        "\n",
        "test.drop(['Index'], axis = 1, inplace = True)\n",
        "\n",
        "#feature_selection\n",
        "y = dataset['Patient_Tag'].tolist()\n",
        "\n",
        "dataset['Story'] = 'a'\n",
        "\n",
        "\n",
        "for i in range(len(dataset)):\n",
        "    dataset.at[i, 'Story'] = dataset['Source'][i] + ' ' + dataset['Host'][i] + ' ' + str(dataset['Link'][i]) + ' ' + dataset['Title'][i] + ' ' + dataset['TRANS_CONV_TEXT'][i]\n",
        "\n",
        "dataset.drop(['Source', 'Host', 'Link', 'Title', 'TRANS_CONV_TEXT'], axis = 1, inplace = True)\n",
        "\n",
        "\n",
        "test['Story'] = 'a'\n",
        "\n",
        "\n",
        "for i in range(len(test)):\n",
        "    test.at[i, 'Story'] = test['Source'][i] + ' ' + test['Host'][i] + ' ' + str(test['Link'][i]) + ' ' + test['Title'][i] + ' ' + test['TRANS_CONV_TEXT'][i]\n",
        "\n",
        "test.drop(['Source', 'Host', 'Link', 'Title', 'TRANS_CONV_TEXT', 'Unnamed: 9'], axis = 1, inplace = True)\n",
        "\n",
        "replace_space = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "bad_symbols = re.compile('[^0-9a-z #+_]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess(text):\n",
        "    text = BeautifulSoup(text, \"lxml\").text # HTML decoding\n",
        "    text = text.lower() # lowercase text\n",
        "    text = replace_space.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text\n",
        "    text = bad_symbols.sub('', text) # delete symbols which are in BAD_SYMBOLS_RE from text\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # delete stopwors from text\n",
        "    return text \n",
        "\n",
        "dataset['Story'] = dataset['Story'].apply(preprocess)\n",
        "test['Story'] = test['Story'].apply(preprocess)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A1X4li_n0YH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_PATH = Path('data/')\n",
        "DATA_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "LABEL_PATH = Path('label/')\n",
        "LABEL_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "MODEL_PATH= Path('models/')\n",
        "MODEL_PATH.mkdir(exist_ok=True)\n",
        "\n",
        "OUTPUT_DIR = MODEL_PATH/'output'\n",
        "OUTPUT_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "sub = pd.read_csv('sample_submission.csv', index_col=None)\n",
        "\n",
        "print(dataset.shape, test.shape, sub.shape)\n",
        "\n",
        "section_ohe = pd.get_dummies(dataset['Patient_Tag'])\n",
        "train = pd.concat((dataset, section_ohe), axis=1)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "test_pct = np.round(len(test)/len(train),2)\n",
        "train_1, valid_1 = train_test_split(train, test_size=test_pct, random_state=424242, stratify=train['Patient_Tag'])\n",
        "\n",
        "print(train_1.shape, valid_1.shape)\n",
        "\n",
        "train_1.to_csv(DATA_PATH/\"train.csv\", index=None)\n",
        "valid_1.to_csv(DATA_PATH/\"valid.csv\", index=None)\n",
        "\n",
        "test.to_csv(\"data/test.csv\", index=None)\n",
        "\n",
        "labels = pd.Series([0, 1])\n",
        "labels.to_csv(\"label/labels.csv\", index=None)\n",
        "\n",
        "print(\"data saved successfully\")\n",
        "\n",
        "del train, section_ohe, train_1, valid_1\n",
        "import gc; gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3_r0KhEosy6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "databunch = BertDataBunch(DATA_PATH, LABEL_PATH,\n",
        "                          tokenizer='xlnet-base-cased',\n",
        "                          train_file='train.csv',\n",
        "                          val_file='valid.csv',\n",
        "                          label_file='labels.csv',\n",
        "                          text_col='Story',\n",
        "                          label_col=['0','1'],\n",
        "                          batch_size_per_gpu=24,\n",
        "                          max_seq_length=256,\n",
        "                          multi_gpu=False,\n",
        "                          multi_label=True,\n",
        "                          model_type='xlnet')\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "import gc; gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e8zaomgZo2Yk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device_cuda = torch.device(\"cuda\")\n",
        "metrics = [{'name': 'accuracy', 'function': accuracy}]\n",
        "\n",
        "learner = BertLearner.from_pretrained_model(\n",
        "                        databunch,\n",
        "                        pretrained_path='xlnet-base-cased',#xlnet-large-cased, bert-base-uncased\n",
        "                        metrics=metrics,\n",
        "                        device=device_cuda,\n",
        "                        logger=logger,\n",
        "                        output_dir=OUTPUT_DIR,\n",
        "                        finetuned_wgts_path=None,\n",
        "                        warmup_steps=500,\n",
        "                        multi_gpu=False,\n",
        "                        is_fp16=True,\n",
        "                        multi_label=False,\n",
        "                        logging_steps=50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-e9Ni0ryuiB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "177650e4-fe7d-499c-e324-394a9df9d746"
      },
      "source": [
        "!pip install apex"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: apex in /usr/local/lib/python3.6/dist-packages (0.9.10.dev0)\n",
            "Requirement already satisfied: cryptacular in /usr/local/lib/python3.6/dist-packages (from apex) (1.5.5)\n",
            "Requirement already satisfied: zope.sqlalchemy in /usr/local/lib/python3.6/dist-packages (from apex) (1.2)\n",
            "Requirement already satisfied: wtforms in /usr/local/lib/python3.6/dist-packages (from apex) (2.2.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from apex) (2.21.0)\n",
            "Requirement already satisfied: pyramid>1.1.2 in /usr/local/lib/python3.6/dist-packages (from apex) (1.10.4)\n",
            "Requirement already satisfied: wtforms-recaptcha in /usr/local/lib/python3.6/dist-packages (from apex) (0.3.2)\n",
            "Requirement already satisfied: pyramid-mailer in /usr/local/lib/python3.6/dist-packages (from apex) (0.15.1)\n",
            "Requirement already satisfied: velruse>=1.0.3 in /usr/local/lib/python3.6/dist-packages (from apex) (1.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from cryptacular->apex) (42.0.2)\n",
            "Requirement already satisfied: pbkdf2 in /usr/local/lib/python3.6/dist-packages (from cryptacular->apex) (1.3)\n",
            "Requirement already satisfied: SQLAlchemy>=0.7 in /usr/local/lib/python3.6/dist-packages (from zope.sqlalchemy->apex) (1.3.12)\n",
            "Requirement already satisfied: transaction>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from zope.sqlalchemy->apex) (3.0.0)\n",
            "Requirement already satisfied: zope.interface>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from zope.sqlalchemy->apex) (4.7.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->apex) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->apex) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->apex) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->apex) (3.0.4)\n",
            "Requirement already satisfied: plaster in /usr/local/lib/python3.6/dist-packages (from pyramid>1.1.2->apex) (1.0)\n",
            "Requirement already satisfied: webob>=1.8.3 in /usr/local/lib/python3.6/dist-packages (from pyramid>1.1.2->apex) (1.8.6)\n",
            "Requirement already satisfied: zope.deprecation>=3.5.0 in /usr/local/lib/python3.6/dist-packages (from pyramid>1.1.2->apex) (4.4.0)\n",
            "Requirement already satisfied: hupper>=1.5 in /usr/local/lib/python3.6/dist-packages (from pyramid>1.1.2->apex) (1.9.1)\n",
            "Requirement already satisfied: translationstring>=0.4 in /usr/local/lib/python3.6/dist-packages (from pyramid>1.1.2->apex) (1.3)\n",
            "Requirement already satisfied: plaster-pastedeploy in /usr/local/lib/python3.6/dist-packages (from pyramid>1.1.2->apex) (0.7)\n",
            "Requirement already satisfied: venusian>=1.0 in /usr/local/lib/python3.6/dist-packages (from pyramid>1.1.2->apex) (3.0.0)\n",
            "Requirement already satisfied: repoze.sendmail>=4.1 in /usr/local/lib/python3.6/dist-packages (from pyramid-mailer->apex) (4.4.1)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.6/dist-packages (from velruse>=1.0.3->apex) (1.3.0)\n",
            "Requirement already satisfied: anykeystore in /usr/local/lib/python3.6/dist-packages (from velruse>=1.0.3->apex) (0.2)\n",
            "Requirement already satisfied: python3-openid in /usr/local/lib/python3.6/dist-packages (from velruse>=1.0.3->apex) (3.1.0)\n",
            "Requirement already satisfied: PasteDeploy>=2.0 in /usr/local/lib/python3.6/dist-packages (from plaster-pastedeploy->pyramid>1.1.2->apex) (2.1.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib->velruse>=1.0.3->apex) (3.1.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from python3-openid->velruse>=1.0.3->apex) (0.6.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN-m4zKppJG7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "61f10d5b-de7c-4a8c-8385-c12c83057ac5"
      },
      "source": [
        "#learner.save_model()\n",
        "learner.fit(epochs=6,\n",
        "            lr=1e-5,\n",
        "            validate=True, \t# Evaluate the model after each epoch\n",
        "            schedule_type=\"warmup_cosine\")\n",
        "\n",
        "learner.save_model()\n",
        "\n",
        "MODEL_PATH_FILE = OUTPUT_DIR/'model_out'\n",
        "\n",
        "predictor = BertClassificationPredictor(\n",
        "                model_path=MODEL_PATH_FILE,\n",
        "                label_path=LABEL_PATH, # location for labels.csv file\n",
        "                multi_label=False,\n",
        "                model_type='xlnet',\n",
        "                do_lower_case=True)\n",
        "\n",
        "\n",
        "texts = list(test['Story'])\n",
        "pred = []\n",
        "pred_probs = []\n",
        "for text in tqdm(texts):\n",
        "    result = predictor.predict(text)\n",
        "    pred.append(int(result[0][0]))\n",
        "    pred_probs.append([prob for label, prob in sorted(result, key=lambda x:x[0])])\n",
        "\n",
        "print(\"test predictions\")\n",
        "print(pd.Series(pred).value_counts())\n",
        "\n",
        "submission = pd.DataFrame()\n",
        "submission['Index'] = index\n",
        "submission['Patient_Tag'] = pd.Series(pred).astype(int)\n",
        "submission.to_csv(\"model_xlnet_base.csv\", index=None)\n",
        "\n",
        "np.save(\"model_xlnet_base_prob.npy\", np.array(pred_probs))\n",
        "\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "valid = pd.read_csv('data/valid.csv', index_col=None)\n",
        "\n",
        "valid_pred = []\n",
        "texts = list(valid['Story'])\n",
        "for text in tqdm(texts):\n",
        "    valid_pred.append(predictor.predict(text)[0][0])\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(valid['Patient_Tag'].values, pd.Series(valid_pred).astype(int)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-cd9f742cda99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m learner.fit(epochs=6,\n\u001b[0m\u001b[1;32m      2\u001b[0m             \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m      \u001b[0;31m# Evaluate the model after each epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m             schedule_type=\"warmup_cosine\")\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'learner' is not defined"
          ]
        }
      ]
    }
  ]
}